{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0NNLJpZJDagxIsaG/UKdW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dho619/TCC_Pos_IA/blob/main/Algoritmo_RN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EWamMHHnYfvi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Para documentação de passo a passo e justificativa dessa função, pode encontrá-la no arquivo TratamentoDosDados.ipynb\n",
        "def TratarDadosBaseWalmart(df):\n",
        "  df.Date=pd.to_datetime(df.Date, format='%d-%m-%Y')\n",
        "  df['Day'] = df.Date.dt.day\n",
        "  df['Month'] = df.Date.dt.month\n",
        "  df['Year'] = df.Date.dt.year\n",
        "  df.drop(['Date'], axis=1, inplace=True)\n",
        "\n",
        "  df.drop_duplicates(inplace=True)\n",
        "\n",
        "  ignoreFeatures = ['Weekly_Sales', 'Day']\n",
        "  maximumToBeCategorical = 45\n",
        "  features = [i for i in df.columns if i not in ignoreFeatures]\n",
        "  uniqueValuesForFeature = df[features].nunique().sort_values()\n",
        "  categoricalFeature = [];\n",
        "  valuesFeature = [];\n",
        "  for i in range(df[features].shape[1]):\n",
        "      if uniqueValuesForFeature.values[i]<=maximumToBeCategorical:\n",
        "          categoricalFeature.append(uniqueValuesForFeature.index[i])\n",
        "      else:\n",
        "          valuesFeature.append(uniqueValuesForFeature.index[i])\n",
        "  for i in categoricalFeature:\n",
        "    if df[i].nunique()==2:\n",
        "        df[i]=pd.get_dummies(df[i], drop_first=True, prefix=str(i))\n",
        "    if (df[i].nunique()>2):\n",
        "        df = pd.concat([df.drop([i], axis=1), pd.DataFrame(pd.get_dummies(df[i], prefix=str(i)))],axis=1)\n",
        "    \n",
        "  return df\n"
      ],
      "metadata": {
        "id": "ADgALciLYtY-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Para documentação de passo a passo e justificativa dessa função, pode encontrá-la no arquivo PreparaçãoDeDados.ipynb\n",
        "\n",
        "def PreparaDados(df):\n",
        "  target = 'Weekly_Sales'\n",
        "\n",
        "  filtro_treino = df[\"Year_2012\"] == 0\n",
        "  filtro_teste = df[\"Year_2012\"] == 1\n",
        "\n",
        "  train = df.where(filtro_treino).dropna()\n",
        "  test =  df.where(filtro_teste).dropna()\n",
        "\n",
        "  y_train = train[target].array\n",
        "  X_train = train.drop([target, \"Year_2010\", \"Year_2011\", \"Year_2012\"],axis=1)\n",
        "  \n",
        "\n",
        "  y_test = test[target].array\n",
        "  X_test = test.drop([target, \"Year_2010\", \"Year_2011\", \"Year_2012\"],axis=1)\n",
        "\n",
        "  X_train.reset_index(drop=True,inplace=True)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "z47fvvABYuC3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./Walmart.csv')\n",
        "df = TratarDadosBaseWalmart(df)\n",
        "\n",
        "X_train, X_test, y_train, y_test = PreparaDados(df)\n",
        "print('Base original  ---> ',df.shape,df.shape,'\\nBase de Treino  ---> ',X_train.shape,y_train.shape,'\\nBase de teste   ---> ', X_test.shape,'', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OWGurTyYyh9",
        "outputId": "5be85b0f-c22b-4bcf-eeed-150d04612645"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base original  --->  (6435, 67) (6435, 67) \n",
            "Base de Treino  --->  (4500, 63) (4500,) \n",
            "Base de teste   --->  (1935, 63)  (1935,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)\n",
        "y_test = y_test.astype(np.float32)\n",
        "#X_train.info()"
      ],
      "metadata": {
        "id": "tE6L0COSZDX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_ = X_train.values;\n",
        "X_test_ = X_test.values;\n",
        "\n",
        "corte = int(len(X_train_)*0.9)\n",
        "X_validation = X_train_[corte:]\n",
        "X_train_ = X_train_[:corte]\n",
        "y_validation = y_train[corte:]\n",
        "y_train = y_train[:corte]"
      ],
      "metadata": {
        "id": "DvCrSePsZE4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    number_features = 63\n",
        "    model = Sequential([\n",
        "        Dense(36, input_shape = (number_features,), activation = 'relu'),\n",
        "        Dense(36, activation = 'relu'),\n",
        "        Dense(360, activation = 'relu'),\n",
        "        Dense(360, activation = 'relu'),\n",
        "        Dense(180, activation = 'relu'),\n",
        "        Dense(180, activation = 'relu'),\n",
        "        Dense(180, activation = 'relu'),\n",
        "        Dense(90, activation = 'relu'),\n",
        "        Dense(90, activation = 'relu'),\n",
        "        Dense(30, activation = 'relu'),\n",
        "        Dense(10, activation = 'relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    \n",
        "    model.compile(\n",
        "         loss = 'mse',\n",
        "         optimizer = 'adam'    \n",
        "            )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "QItA1c1KZGtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model2():\n",
        "    number_features = 63\n",
        "    model = Sequential([\n",
        "        Dense(64, input_shape = (number_features,), activation = 'relu'),\n",
        "        Dense(64, activation = 'relu'),\n",
        "        Dense(320, activation = 'relu'),\n",
        "        Dense(320, activation = 'relu'),\n",
        "        Dense(160, activation = 'relu'),\n",
        "        Dense(160, activation = 'relu'),\n",
        "        Dense(160, activation = 'relu'),\n",
        "        Dense(80, activation = 'relu'),\n",
        "        Dense(80, activation = 'relu'),\n",
        "        Dense(20, activation = 'relu'),\n",
        "        Dense(10, activation = 'relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "    model.compile(\n",
        "         loss = 'mse',\n",
        "         optimizer = optimizer,    \n",
        "         metrics=['mae', 'mse'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Hsut59BoZISU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model2()\n",
        "history = model.fit(\n",
        "        X_train_,y_train,\n",
        "        validation_data =(X_validation, y_validation),\n",
        "        epochs = 100\n",
        ")"
      ],
      "metadata": {
        "id": "GWO3H8bQZLV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "r2_score(y_test, predictions), mean_absolute_error(y_test, predictions), np.sqrt(mean_squared_error(y_test, predictions))"
      ],
      "metadata": {
        "id": "9Om8DczYZNV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (36, 10)) \n",
        "plt.plot(predictions, 'b')\n",
        "plt.plot(y_test, 'r')\n",
        "plt.title(\"Redes Neurais\", fontsize=40)\n",
        "plt.xlabel(\"Valor\", fontsize=30)\n",
        "plt.ylabel(\"Valor de venda em milhões\", fontsize=30)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V1dAoPLjZPi-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}