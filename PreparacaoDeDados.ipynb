{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreparaçãoDeDados.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMeFVN9lM69A6HF9XoFPPNY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dho619/TCC_Pos_IA/blob/main/PreparacaoDeDados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "gKilDIkEY2VB"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "NxSz4xTGAm1g"
      },
      "outputs": [],
      "source": [
        "#Para documentação de passo a passo e justificativa dessa função, pode encontrá-la no arquivo TratamentoDosDados.ipynb\n",
        "def TratarDadosBaseWalmart(df):\n",
        "  df.Date=pd.to_datetime(df.Date, format='%d-%m-%Y')\n",
        "  df['Day'] = df.Date.dt.day\n",
        "  df['Month'] = df.Date.dt.month\n",
        "  df['Year'] = df.Date.dt.year\n",
        "  df.drop(['Date'], axis=1, inplace=True)\n",
        "\n",
        "  df.drop_duplicates(inplace=True)\n",
        "\n",
        "  ignoreFeatures = ['Weekly_Sales', 'Day']\n",
        "  maximumToBeCategorical = 45\n",
        "  features = [i for i in df.columns if i not in ignoreFeatures]\n",
        "  uniqueValuesForFeature = df[features].nunique().sort_values()\n",
        "  categoricalFeature = [];\n",
        "  valuesFeature = [];\n",
        "  for i in range(df[features].shape[1]):\n",
        "      if uniqueValuesForFeature.values[i]<=maximumToBeCategorical:\n",
        "          categoricalFeature.append(uniqueValuesForFeature.index[i])\n",
        "      else:\n",
        "          valuesFeature.append(uniqueValuesForFeature.index[i])\n",
        "  for i in categoricalFeature:\n",
        "    if df[i].nunique()==2:\n",
        "        df[i]=pd.get_dummies(df[i], drop_first=True, prefix=str(i))\n",
        "    if (df[i].nunique()>2):\n",
        "        df = pd.concat([df.drop([i], axis=1), pd.DataFrame(pd.get_dummies(df[i], prefix=str(i)))],axis=1)\n",
        "    \n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./Walmart.csv')\n",
        "df = TratarDadosBaseWalmart(df)\n",
        "\n",
        "target = 'Weekly_Sales'\n",
        "features = [i for i in df.columns if i not in [target]]"
      ],
      "metadata": {
        "id": "4JmkG1RKZT7G"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NormalizarValores(df, columns):\n",
        "  for column in columns:\n",
        "    df[column] = df[column]/df[column].max()\n",
        "\n",
        "def PertenceAMesmaLoja(df, num1, num2):\n",
        "  if num1 < 0 or num2 < 0: return False\n",
        "  for i in range(1, 46):\n",
        "    if df[\"Store_\" + str(i)][num1] != df[\"Store_\" + str(i)][num2]: return False\n",
        "  return True\n",
        "\n",
        "df[\"SalesOneWeekAgo\"] = np.zeros(len(df[target]))\n",
        "df[\"SalesTwoWeeksAgo\"] = np.zeros(len(df[target]))\n",
        "df[\"SalesThreeWeeksAgo\"] = np.zeros(len(df[target]))\n",
        "\n",
        "for i, _ in enumerate(df[target]):\n",
        "  df[\"SalesOneWeekAgo\"][i] = df[target][i-1] if PertenceAMesmaLoja(df, i, i-1) else df[target][i]\n",
        "  df[\"SalesTwoWeeksAgo\"][i] = df[target][i-2] if PertenceAMesmaLoja(df, i, i-2) else df[target][i]\n",
        "  df[\"SalesThreeWeeksAgo\"][i] = df[target][i-3] if PertenceAMesmaLoja(df, i, i-3) else df[target][i]\n",
        "\n",
        "#Normalizando valores\n",
        "columns = [\"Temperature\", \"Fuel_Price\", \"CPI\", \"Unemployment\"]\n",
        "NormalizarValores(df, columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfYIPzc_ExZA",
        "outputId": "4badeaa5-24ee-4758-ab56-9ce5aee99153"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separando base de treino e teste"
      ],
      "metadata": {
        "id": "UEO7b0h5bVVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtro_treino = df[\"Year_2012\"] == 0\n",
        "filtro_teste = df[\"Year_2012\"] == 1\n",
        "\n",
        "Train = df.where(filtro_treino).dropna()\n",
        "Test =  df.where(filtro_teste).dropna()\n",
        "\n",
        "#Dropando o campo a ser previsto e o campos de anos para o ano não influenciar nas decisões\n",
        "#de acordo com os resultados, pode ser que eu volte o campo de ano, para testes\n",
        "# o dia em primeiro momento vou deixar, mas pode ser que eu tire, parar validar nos testes.\n",
        "Train_Y = Train[target]\n",
        "Train_X = Train.drop([target, \"Year_2010\", \"Year_2011\", \"Year_2012\"],axis=1)\n",
        "\n",
        "Test_Y = Test[target]\n",
        "Test_X = Test.drop([target, \"Year_2010\", \"Year_2011\", \"Year_2012\"],axis=1)\n",
        "\n",
        "Train_X.reset_index(drop=True,inplace=True)\n",
        "\n",
        "print('Base original  ---> ',df.shape,df.shape,'\\nBase de Treino  ---> ',Train_X.shape,Train_Y.shape,'\\nBase de teste   ---> ', Test_X.shape,'', Test_Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRmHGx6RBN71",
        "outputId": "588afb4c-959f-4bf1-afd4-f88976d0b089"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base original  --->  (6435, 70) (6435, 70) \n",
            "Base de Treino  --->  (4500, 66) (4500,) \n",
            "Base de teste   --->  (1935, 66)  (1935,)\n"
          ]
        }
      ]
    }
  ]
}